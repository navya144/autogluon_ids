{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combine the data files into a single df containing attack and benign data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Friday-WorkingHours-Afternoon-DDos.pcap_ISCX.csv\n",
      "Friday-WorkingHours-Afternoon-PortScan.pcap_ISCX.csv\n",
      "Friday-WorkingHours-Morning.pcap_ISCX.csv\n",
      "Monday-WorkingHours.pcap_ISCX.csv\n",
      "Thursday-WorkingHours-Afternoon-Infilteration.pcap_ISCX.csv\n",
      "Thursday-WorkingHours-Morning-WebAttacks.pcap_ISCX.csv\n",
      "Tuesday-WorkingHours.pcap_ISCX.csv\n",
      "Wednesday-workingHours.pcap_ISCX.csv\n"
     ]
    }
   ],
   "source": [
    "from autogluon.tabular import TabularDataset, TabularPredictor\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from df_helpers import non_persistent_preprocessing\n",
    "\n",
    "np.random.seed(29)\n",
    "\n",
    "non_persistent_file_names = ['Friday-WorkingHours-Afternoon-DDos.pcap_ISCX.csv', \n",
    "           'Friday-WorkingHours-Afternoon-PortScan.pcap_ISCX.csv',\n",
    "           'Friday-WorkingHours-Morning.pcap_ISCX.csv',\n",
    "           'Monday-WorkingHours.pcap_ISCX.csv',\n",
    "           'Thursday-WorkingHours-Afternoon-Infilteration.pcap_ISCX.csv',\n",
    "           'Thursday-WorkingHours-Morning-WebAttacks.pcap_ISCX.csv',\n",
    "           'Tuesday-WorkingHours.pcap_ISCX.csv',\n",
    "           'Wednesday-workingHours.pcap_ISCX.csv'\n",
    "]\n",
    "\n",
    "df = pd.DataFrame()\n",
    "\n",
    "for file in non_persistent_file_names:\n",
    "    print(file)\n",
    "    df_temp = TabularDataset('non-persistent/'+file)\n",
    "    df_temp.replace([np.inf, -np.inf], np.nan, inplace=True) \n",
    "    df_temp.dropna(inplace=True)\n",
    "    df = pd.concat([df_temp, df])\n",
    "\n",
    "df = df.sample(frac=1)\n",
    "\n",
    "# Remove duplicate column and whitespace from all columns\n",
    "df = non_persistent_preprocessing(df)\n",
    "    \n",
    "df.reset_index(inplace=True, drop=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Drop data for some uncommon threat types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "benign_df = df.loc[df['Label'] == 'BENIGN']\n",
    "malicious_df = df.loc[df['Label'] != 'BENIGN'].copy(deep=True)\n",
    "\n",
    "malicious_df.drop(malicious_df[malicious_df['Label'] == 'Heartbleed'].index, inplace=True)\n",
    "malicious_df.drop(malicious_df[malicious_df['Label'] == 'Web Attack � Sql Injection'].index, inplace=True)\n",
    "malicious_df.drop(malicious_df[malicious_df['Label'] == 'Infiltration'].index, inplace=True)\n",
    "malicious_df.drop(malicious_df[malicious_df['Label'] == 'Web Attack � XSS'].index, inplace=True)\n",
    "malicious_df.drop(malicious_df[malicious_df['Label'] == 'Web Attack � Brute Force'].index, inplace=True)\n",
    "malicious_df.drop(malicious_df[malicious_df['Label'] == 'Bot'].index, inplace=True)\n",
    "\n",
    "merged_df = pd.concat([benign_df, malicious_df])\n",
    "merged_df = merged_df.sample(frac=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Label\n",
       "BENIGN              2271320\n",
       "DoS Hulk             230124\n",
       "PortScan             158804\n",
       "DDoS                 128025\n",
       "DoS GoldenEye         10293\n",
       "FTP-Patator            7935\n",
       "SSH-Patator            5897\n",
       "DoS slowloris          5796\n",
       "DoS Slowhttptest       5499\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df['Label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split the df into Train and Test dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "slice_size = int(0.75 * len(merged_df))\n",
    "combined_train_df = merged_df[:slice_size].copy(deep=True)\n",
    "combined_test_df = merged_df[slice_size:].copy(deep=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20250416_051117\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.2\n",
      "Python Version:     3.11.8\n",
      "Operating System:   Darwin\n",
      "Platform Machine:   arm64\n",
      "Platform Version:   Darwin Kernel Version 24.3.0: Thu Jan  2 20:22:58 PST 2025; root:xnu-11215.81.4~3/RELEASE_ARM64_T8132\n",
      "CPU Count:          10\n",
      "Memory Avail:       2.97 GB / 16.00 GB (18.6%)\n",
      "Disk Space Avail:   282.59 GB / 460.43 GB (61.4%)\n",
      "===================================================\n",
      "Presets specified: ['medium_quality']\n",
      "Beginning AutoGluon training ... Time limit = 60s\n",
      "AutoGluon will save models to \"/Users/navya/Documents/Uni/Repos/autogluon_ids/AutogluonModels/ag-20250416_051117\"\n",
      "Train Data Rows:    4000\n",
      "Train Data Columns: 78\n",
      "Label Column:       Label\n",
      "AutoGluon infers your prediction problem is: 'multiclass' (because dtype of label-column == object).\n",
      "\t9 unique label values:  ['DoS Hulk', 'PortScan', 'DDoS', 'FTP-Patator', 'DoS GoldenEye', 'DoS Slowhttptest', 'DoS slowloris', 'SSH-Patator', 'BENIGN']\n",
      "\tIf 'multiclass' is not the correct problem_type, please manually specify the problem_type parameter during Predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression', 'quantile'])\n",
      "Problem Type:       multiclass\n",
      "Preprocessing data ...\n",
      "Train Data Class Count: 9\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    3074.72 MB\n",
      "\tTrain Data (Original)  Memory Usage: 3.40 MB (0.1% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 6 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\t\tFitting DatetimeFeatureGenerator...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUseless Original Features (Count: 12): ['Bwd PSH Flags', 'Fwd URG Flags', 'Bwd URG Flags', 'RST Flag Count', 'CWE Flag Count', 'ECE Flag Count', 'Fwd Avg Bytes/Bulk', 'Fwd Avg Packets/Bulk', 'Fwd Avg Bulk Rate', 'Bwd Avg Bytes/Bulk', 'Bwd Avg Packets/Bulk', 'Bwd Avg Bulk Rate']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tUnused Original Features (Count: 5): ['SYN Flag Count', 'Subflow Fwd Packets', 'Subflow Fwd Bytes', 'Subflow Bwd Packets', 'Subflow Bwd Bytes']\n",
      "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
      "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\t\t('int', []) : 5 | ['SYN Flag Count', 'Subflow Fwd Packets', 'Subflow Fwd Bytes', 'Subflow Bwd Packets', 'Subflow Bwd Bytes']\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])                      : 41 | ['Total Length of Fwd Packets', 'Total Length of Bwd Packets', 'Fwd Packet Length Max', 'Fwd Packet Length Min', 'Fwd Packet Length Mean', ...]\n",
      "\t\t('int', [])                        : 16 | ['Source Port', 'Destination Port', 'Protocol', 'Flow Duration', 'Total Fwd Packets', ...]\n",
      "\t\t('object', [])                     :  3 | ['Flow ID', 'Source IP', 'Destination IP']\n",
      "\t\t('object', ['datetime_as_object']) :  1 | ['Timestamp']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', [])             :  3 | ['Flow ID', 'Source IP', 'Destination IP']\n",
      "\t\t('float', [])                : 41 | ['Total Length of Fwd Packets', 'Total Length of Bwd Packets', 'Fwd Packet Length Max', 'Fwd Packet Length Min', 'Fwd Packet Length Mean', ...]\n",
      "\t\t('int', [])                  : 11 | ['Source Port', 'Destination Port', 'Protocol', 'Flow Duration', 'Total Fwd Packets', ...]\n",
      "\t\t('int', ['bool'])            :  5 | ['Fwd PSH Flags', 'FIN Flag Count', 'PSH Flag Count', 'ACK Flag Count', 'URG Flag Count']\n",
      "\t\t('int', ['datetime_as_int']) :  3 | ['Timestamp', 'Timestamp.month', 'Timestamp.dayofweek']\n",
      "\t0.4s = Fit runtime\n",
      "\t61 features in original data used to generate 63 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 1.71 MB (0.1% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.44s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'mcc'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.125, Train Rows: 3500, Val Rows: 500\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{}],\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
      "\t'CAT': [{}],\n",
      "\t'XGB': [{}],\n",
      "\t'FASTAI': [{}],\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "Fitting 13 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: KNeighborsUnif ... Training model for up to 59.56s of the 59.55s of remaining time.\n",
      "\t0.8786\t = Validation score   (mcc)\n",
      "\t2.68s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist ... Training model for up to 56.79s of the 56.79s of remaining time.\n",
      "\t0.8824\t = Validation score   (mcc)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI ... Training model for up to 56.78s of the 56.78s of remaining time.\n",
      "Metric mcc is not supported by this model - using log_loss instead\n",
      "\t0.9972\t = Validation score   (mcc)\n",
      "\t2.47s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: LightGBMXT ... Training model for up to 54.30s of the 54.30s of remaining time.\n",
      "\t0.9972\t = Validation score   (mcc)\n",
      "\t7.94s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: LightGBM ... Training model for up to 46.35s of the 46.35s of remaining time.\n",
      "\t1.0\t = Validation score   (mcc)\n",
      "\t6.46s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: RandomForestGini ... Training model for up to 39.89s of the 39.89s of remaining time.\n",
      "\t1.0\t = Validation score   (mcc)\n",
      "\t0.5s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr ... Training model for up to 39.35s of the 39.35s of remaining time.\n",
      "\t1.0\t = Validation score   (mcc)\n",
      "\t0.28s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: CatBoost ... Training model for up to 39.04s of the 39.04s of remaining time.\n",
      "\tRan out of time, early stopping on iteration 1449.\n",
      "\t1.0\t = Validation score   (mcc)\n",
      "\t39.03s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 60.01s ... Best model: LightGBM | Estimated inference throughput: 287045.2 rows/s (500 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/Users/navya/Documents/Uni/Repos/autogluon_ids/AutogluonModels/ag-20250416_051117\")\n"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "all_results = []\n",
    "# for train_data_size in range(2000, 6000, 2000):\n",
    "train_data_size = 2000\n",
    "combined_train_df_slice = pd.DataFrame()\n",
    "for malicious_label_name in list(malicious_df['Label'].unique()):\n",
    "    malicious_slice = malicious_df.loc[malicious_df['Label'] == malicious_label_name][:int(train_data_size/8)]\n",
    "    combined_train_df_slice = pd.concat([combined_train_df_slice, malicious_slice])\n",
    "combined_train_df_slice = pd.concat([combined_train_df_slice, benign_df[:train_data_size]])\n",
    "\n",
    "print(len(combined_train_df_slice))\n",
    "\n",
    "predictor = TabularPredictor(label='Label', eval_metric='mcc').fit(combined_train_df_slice, time_limit=60, presets='medium_quality', fit_weighted_ensemble=False)\n",
    "\n",
    "y_pred = predictor.predict(combined_test_df.drop(columns=['Label']))\n",
    "all_results.append(predictor.evaluate(combined_test_df, silent=True))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'mcc': 0.9951828646704585,\n",
       "  'accuracy': 0.9983595967837897,\n",
       "  'balanced_accuracy': 0.995377847903598}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Export Non Persistent Multiclass classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cloned TabularPredictor located in '/Users/navya/Documents/Uni/Repos/autogluon_ids/AutogluonModels/ag-20250416_051117' to 'non-persistent-multiclass-classifier'.\n",
      "\tTo load the cloned predictor: predictor_clone = TabularPredictor.load(path=\"non-persistent-multiclass-classifier\")\n",
      "Clone: Keeping minimum set of models required to predict with best model 'LightGBM'...\n",
      "Deleting model KNeighborsUnif. All files under /Users/navya/Documents/Uni/Repos/autogluon_ids/non-persistent-multiclass-classifier/models/KNeighborsUnif will be removed.\n",
      "Deleting model KNeighborsDist. All files under /Users/navya/Documents/Uni/Repos/autogluon_ids/non-persistent-multiclass-classifier/models/KNeighborsDist will be removed.\n",
      "Deleting model NeuralNetFastAI. All files under /Users/navya/Documents/Uni/Repos/autogluon_ids/non-persistent-multiclass-classifier/models/NeuralNetFastAI will be removed.\n",
      "Deleting model LightGBMXT. All files under /Users/navya/Documents/Uni/Repos/autogluon_ids/non-persistent-multiclass-classifier/models/LightGBMXT will be removed.\n",
      "Deleting model RandomForestGini. All files under /Users/navya/Documents/Uni/Repos/autogluon_ids/non-persistent-multiclass-classifier/models/RandomForestGini will be removed.\n",
      "Deleting model RandomForestEntr. All files under /Users/navya/Documents/Uni/Repos/autogluon_ids/non-persistent-multiclass-classifier/models/RandomForestEntr will be removed.\n",
      "Deleting model CatBoost. All files under /Users/navya/Documents/Uni/Repos/autogluon_ids/non-persistent-multiclass-classifier/models/CatBoost will be removed.\n",
      "Clone: Removing artifacts unnecessary for prediction. NOTE: Clone can no longer fit new models, and most functionality except for predict and predict_proba will no longer work\n"
     ]
    }
   ],
   "source": [
    "save_path_clone_opt = \"non-persistent-multiclass-classifier\"\n",
    "# will return the path to the cloned predictor, identical to save_path_clone_opt\n",
    "path_clone_opt = predictor.clone_for_deployment(path=save_path_clone_opt)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
